{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ec5669cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0bc0b25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET OVERVIEW\n",
      "Dataset shape: 11000 samples, 19 features\n",
      "\n",
      "Feature Overview:\n",
      "Target variable: Anxiety Level (1-10) - Anxiety level on scale 1-10\n",
      "Numerical features (11):\n",
      "  - Age: range 18.0-64.0, mean 40.41\n",
      "  - Sleep Hours: range 0.2-12.5, mean 6.77\n",
      "  - Physical Activity (hrs/week): range 0.0-11.2, mean 2.92\n",
      "  - Caffeine Intake (mg/day): range 0.0-599.0, mean 313.29\n",
      "  - Alcohol Consumption (drinks/week): range 0.0-19.0, mean 9.73\n",
      "  - Stress Level (1-10): range 1.0-10.0, mean 5.81\n",
      "  - Heart Rate (bpm): range 60.0-119.0, mean 90.99\n",
      "  - Breathing Rate (breaths/min): range 12.0-29.0, mean 20.79\n",
      "  - Sweating Level (1-5): range 1.0-5.0, mean 3.08\n",
      "  - Therapy Sessions (per month): range 0.0-9.0, mean 4.68\n",
      "  - Diet Quality (1-10): range 1.0-10.0, mean 5.21\n",
      "Categorical features (7):\n",
      "  - Gender: 3 unique values\n",
      "  - Occupation: 13 unique values\n",
      "  - Smoking: 2 unique values\n",
      "  - Family History of Anxiety: 2 unique values\n",
      "  - Dizziness: 2 unique values\n",
      "  - Medication: 2 unique values\n",
      "  - Recent Major Life Event: 2 unique values\n",
      "Training set: 8800 samples, Test set: 2200 samples\n"
     ]
    }
   ],
   "source": [
    "# Create output directory for plots if it doesn't exist\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "print(\"DATASET OVERVIEW\")\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/anxiety level.csv\")\n",
    "print(f\"Dataset shape: {df.shape[0]} samples, {df.shape[1]} features\")\n",
    "# Describe dataset features and types\n",
    "target_col = 'Anxiety Level (1-10)'\n",
    "X = df.drop(target_col, axis=1)\n",
    "y = df[target_col]\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"\\nFeature Overview:\")\n",
    "print(f\"Target variable: {target_col} - Anxiety level on scale 1-10\")\n",
    "print(f\"Numerical features ({len(num_cols)}):\")\n",
    "for col in num_cols:\n",
    "    print(f\"  - {col}: range {X[col].min():.1f}-{X[col].max():.1f}, mean {X[col].mean():.2f}\")\n",
    "print(f\"Categorical features ({len(cat_cols)}):\")\n",
    "for col in cat_cols:\n",
    "    print(f\"  - {col}: {X[col].nunique()} unique values\")\n",
    "\n",
    "# Split data FIRST (to avoid data leakage)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training set: {X_train.shape[0]} samples, Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e62aeae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXPLORATORY DATA ANALYSIS\n",
      "No missing values found\n",
      "\n",
      "Target Variable (Anxiety Level) Analysis:\n",
      "Mean: 4.15, Median: 4.00, Min: 1.0, Max: 10.0\n",
      "Distribution: {1.0: 806, 2.0: 1524, 3.0: 2278, 4.0: 2467, 5.0: 1816, 6.0: 821, 7.0: 246, 8.0: 348, 9.0: 364, 10.0: 330}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEXPLORATORY DATA ANALYSIS\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = X.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(\"Missing values per column:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "else:\n",
    "    print(\"No missing values found\")\n",
    "\n",
    "# Target variable analysis\n",
    "print(f\"\\nTarget Variable (Anxiety Level) Analysis:\")\n",
    "print(f\"Mean: {y.mean():.2f}, Median: {y.median():.2f}, Min: {y.min()}, Max: {y.max()}\")\n",
    "print(f\"Distribution: {y.value_counts().sort_index().to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "efb6d7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved target variable distribution plot to 'plots/anxiety_distribution.png'\n"
     ]
    }
   ],
   "source": [
    "# Create visualization for target variable\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(y, kde=True, bins=10)\n",
    "plt.title('Distribution of Anxiety Level')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=y)\n",
    "plt.title('Boxplot of Anxiety Level')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/anxiety_distribution.png')\n",
    "plt.close()\n",
    "print(\"Saved target variable distribution plot to 'plots/anxiety_distribution.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1d38b1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 correlations with Anxiety Level:\n",
      "Stress Level (1-10): 0.6570\n",
      "Sleep Hours: -0.4673\n",
      "Caffeine Intake (mg/day): 0.2810\n",
      "Therapy Sessions (per month): 0.2626\n",
      "Physical Activity (hrs/week): -0.2259\n"
     ]
    }
   ],
   "source": [
    "# Correlation analysis\n",
    "correlations = []\n",
    "for col in num_cols:\n",
    "    corr = X_train[col].corr(y_train)\n",
    "    correlations.append((col, corr))\n",
    "correlations.sort(key=lambda x: abs(x[1]), reverse=True) # To get the heighst correlation first\n",
    "\n",
    "# for col, corr in correlations:\n",
    "#     print(f\"{col}: {corr:.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 correlations with Anxiety Level:\") \n",
    "for col, corr in correlations[:5]: # taking only top 5 correlations\n",
    "    print(f\"{col}: {corr:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7561bcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved correlation plot to 'plots/top_correlations.png'\n"
     ]
    }
   ],
   "source": [
    "# Visualize top correlations\n",
    "plt.figure(figsize=(12, 5))\n",
    "corr_df = pd.DataFrame(correlations, columns=['Feature', 'Correlation'])\n",
    "sns.barplot(x='Correlation', y='Feature', data=corr_df.head(10)) # Plotting the top 10 correlations\n",
    "plt.title('Top 10 Features Correlated with Anxiety Level')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/top_correlations.png')\n",
    "plt.close()\n",
    "print(\"Saved correlation plot to 'plots/top_correlations.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "51d3d7fe",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9   \\\n",
       "0    True   True   True   True   True   True   True   True   True   True   \n",
       "1   False   True   True   True   True   True   True   True   True   True   \n",
       "2   False  False   True   True   True   True   True   True   True   True   \n",
       "3   False  False  False   True   True   True   True   True   True   True   \n",
       "4   False  False  False  False   True   True   True   True   True   True   \n",
       "5   False  False  False  False  False   True   True   True   True   True   \n",
       "6   False  False  False  False  False  False   True   True   True   True   \n",
       "7   False  False  False  False  False  False  False   True   True   True   \n",
       "8   False  False  False  False  False  False  False  False   True   True   \n",
       "9   False  False  False  False  False  False  False  False  False   True   \n",
       "10  False  False  False  False  False  False  False  False  False  False   \n",
       "11  False  False  False  False  False  False  False  False  False  False   \n",
       "\n",
       "       10    11  \n",
       "0    True  True  \n",
       "1    True  True  \n",
       "2    True  True  \n",
       "3    True  True  \n",
       "4    True  True  \n",
       "5    True  True  \n",
       "6    True  True  \n",
       "7    True  True  \n",
       "8    True  True  \n",
       "9    True  True  \n",
       "10   True  True  \n",
       "11  False  True  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing upper traingle of matrix look\n",
    "np.triu(np.ones([4,4])) \n",
    "\n",
    "# making upper traingle of boolean matrix \n",
    "pd.DataFrame(np.triu(np.ones_like(corr_matrix, dtype=bool))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b85f9a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved correlation heatmap to 'plots/correlation_heatmap.png'\n"
     ]
    }
   ],
   "source": [
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "corr_matrix = df[num_cols + [target_col]].corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "# mask is a boolean matrix with the same shape as corr_matrix\n",
    "# with True values in the upper triangle and False values in the lower triangle\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', linewidths = 0.5) \n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/correlation_heatmap.png')\n",
    "plt.close()\n",
    "print(\"Saved correlation heatmap to 'plots/correlation_heatmap.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3adf3fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key EDA Insights:\n",
      "# Most factors that increase anxiety\n",
      "   - Stress Level (1-10) increases anxiety (correlation: 0.66)\n",
      "   - Sleep Hours decreases anxiety (correlation: -0.47)\n",
      "   - Caffeine Intake (mg/day) increases anxiety (correlation: 0.28)\n"
     ]
    }
   ],
   "source": [
    "# Key insights from EDA\n",
    "print(\"\\nKey EDA Insights:\")\n",
    "print(\"# Most factors that increase anxiety\")\n",
    "for col, corr in correlations[:3]:\n",
    "    direction = \"increases\" if corr > 0 else \"decreases\"\n",
    "    print(f\"   - {col} {direction} anxiety (correlation: {corr:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8a083763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety level distribution shape\n",
      "   - Skewness: 0.92 (positively skewed)\n"
     ]
    }
   ],
   "source": [
    "print(\"Anxiety level distribution shape\")\n",
    "skewness = y.skew()\n",
    "print(f\"   - Skewness: {skewness:.2f} ({'positively skewed' if skewness > 0 else 'negatively skewed' if skewness < 0 else 'symmetric'})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b685994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATA CLEANING\n",
      "Sleep Hours: 24 outliers (0.3%)\n",
      "Physical Activity (hrs/week): 19 outliers (0.2%)\n",
      "Completed data preprocessing (encoding and scaling)\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDATA CLEANING\")\n",
    "# Handle outliers\n",
    "def identify_outliers(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return series[(series < lower_bound) | (series > upper_bound)]\n",
    "\n",
    "# Detect outliers in numerical features\n",
    "outlier_counts = {}\n",
    "for col in num_cols:\n",
    "    outliers = identify_outliers(X_train[col])\n",
    "    if len(outliers) > 0:\n",
    "        outlier_counts[col] = len(outliers)\n",
    "        print(f\"{col}: {len(outliers)} outliers ({len(outliers)/len(X_train)*100:.1f}%)\")\n",
    "\n",
    "# Create preprocessing steps\n",
    "# One-hot encode categorical features\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=cat_cols, drop_first=True)\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Ensure test set has same columns as train set\n",
    "for col in X_train_encoded.columns:\n",
    "    if col not in X_test_encoded.columns:\n",
    "        X_test_encoded[col] = 0\n",
    "X_test_encoded = X_test_encoded[X_train_encoded.columns]\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train_encoded.copy()\n",
    "X_test_scaled = X_test_encoded.copy()\n",
    "X_train_scaled[num_cols] = scaler.fit_transform(X_train_scaled[num_cols])\n",
    "X_test_scaled[num_cols] = scaler.transform(X_test_scaled[num_cols])\n",
    "print(\"Completed data preprocessing (encoding and scaling)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2d4589db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DIMENSIONALITY REDUCTION\n",
      "Applying Principal Component Analysis (PCA):\n",
      "PCA reduced dimensions from 11 to 11 components\n",
      "Explained variance: 1.00\n",
      "Component contribution:\n",
      "  - PC1: 0.1523 (15.2% of variance)\n",
      "  - PC2: 0.0929 (9.3% of variance)\n",
      "  - PC3: 0.0897 (9.0% of variance)\n",
      "  - PC4: 0.0875 (8.7% of variance)\n",
      "  - PC5: 0.0868 (8.7% of variance)\n",
      "  - PC6: 0.0862 (8.6% of variance)\n",
      "  - PC7: 0.0847 (8.5% of variance)\n",
      "  - PC8: 0.0835 (8.4% of variance)\n",
      "  - PC9: 0.0823 (8.2% of variance)\n",
      "  - PC10: 0.0791 (7.9% of variance)\n",
      "  - PC11: 0.0750 (7.5% of variance)\n",
      "Saved PCA variance plot to 'plots/pca_variance.png'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDIMENSIONALITY REDUCTION\")\n",
    "# Use PCA for numerical features only\n",
    "print(\"Applying Principal Component Analysis (PCA):\")\n",
    "pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "X_train_num_pca = pca.fit_transform(X_train_scaled[num_cols])\n",
    "X_test_num_pca = pca.transform(X_test_scaled[num_cols])\n",
    "\n",
    "print(f\"PCA reduced dimensions from {len(num_cols)} to {pca.n_components_} components\")\n",
    "print(f\"Explained variance: {np.sum(pca.explained_variance_ratio_):.2f}\")\n",
    "print(f\"Component contribution:\")\n",
    "for i, var in enumerate(pca.explained_variance_ratio_):\n",
    "    print(f\"  - PC{i+1}: {var:.4f} ({var*100:.1f}% of variance)\")\n",
    "\n",
    "# Visualize explained variance\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by PCA Components')\n",
    "plt.savefig('plots/pca_variance.png')\n",
    "plt.close()\n",
    "print(\"Saved PCA variance plot to 'plots/pca_variance.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "92ee207b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODELING PIPELINE\n",
      "Creating modeling pipeline with preprocessing and model training steps:\n",
      "1. One-hot encoding of categorical features\n",
      "2. Standardization of numerical features\n",
      "3. Linear regression model fitting\n",
      "4. Model evaluation\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMODELING PIPELINE\")\n",
    "print(\"Creating modeling pipeline with preprocessing and model training steps:\")\n",
    "print(\"1. One-hot encoding of categorical features\")\n",
    "print(\"2. Standardization of numerical features\")\n",
    "print(\"3. Linear regression model fitting\")\n",
    "print(\"4. Model evaluation\")\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"{name}: R² = {r2:.4f}, RMSE = {rmse:.4f}, MAE = {mae:.4f}\")\n",
    "    return model, y_pred, r2, rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "002f02fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HYPERPARAMETER TUNING AND EVALUATION\n",
      "\n",
      "Baseline Linear Regression:\n",
      "Linear Regression: R² = 0.6773, RMSE = 1.2172, MAE = 0.9643\n",
      "\n",
      "Ridge Regression with hyperparameter tuning:\n",
      "Ridge (alpha=0.01): R² = 0.6773, RMSE = 1.2172, MAE = 0.9643\n",
      "Ridge (alpha=0.1): R² = 0.6773, RMSE = 1.2172, MAE = 0.9643\n",
      "Ridge (alpha=1.0): R² = 0.6773, RMSE = 1.2172, MAE = 0.9643\n",
      "Ridge (alpha=10.0): R² = 0.6773, RMSE = 1.2172, MAE = 0.9643\n",
      "Ridge (alpha=100.0): R² = 0.6772, RMSE = 1.2173, MAE = 0.9642\n",
      "Best Ridge model: alpha=0.01, R² = 0.6773\n",
      "\n",
      "Lasso Regression with hyperparameter tuning:\n",
      "Lasso (alpha=0.001): R² = 0.6773, RMSE = 1.2172, MAE = 0.9641\n",
      "Lasso (alpha=0.01): R² = 0.6764, RMSE = 1.2187, MAE = 0.9652\n",
      "Lasso (alpha=0.1): R² = 0.6568, RMSE = 1.2552, MAE = 0.9839\n",
      "Lasso (alpha=1.0): R² = 0.2057, RMSE = 1.9096, MAE = 1.4225\n",
      "Lasso (alpha=10.0): R² = -0.0002, RMSE = 2.1428, MAE = 1.6146\n",
      "Best Lasso model: alpha=0.001, R² = 0.6773\n",
      "\n",
      "Best model: Linear Regression (R² = 0.6773, RMSE = 1.2172)\n",
      "Saved actual vs predicted plot to 'plots/actual_vs_predicted.png'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nHYPERPARAMETER TUNING AND EVALUATION\")\n",
    "\n",
    "# Base Linear Regression (no hyperparameters to tune)\n",
    "print(\"\\nBaseline Linear Regression:\")\n",
    "lr_model, lr_pred, lr_r2, lr_rmse, lr_mae = evaluate_model(\n",
    "    \"Linear Regression\", LinearRegression(), \n",
    "    X_train_scaled, X_test_scaled, y_train, y_test\n",
    ")\n",
    "\n",
    "# Ridge Regression with hyperparameter tuning\n",
    "print(\"\\nRidge Regression with hyperparameter tuning:\")\n",
    "ridge_alphas = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "best_ridge_r2 = -np.inf\n",
    "best_ridge_alpha = None\n",
    "best_ridge_model = None\n",
    "\n",
    "for alpha in ridge_alphas:\n",
    "    model, pred, r2, rmse, mae = evaluate_model(\n",
    "        f\"Ridge (alpha={alpha})\", Ridge(alpha=alpha),\n",
    "        X_train_scaled, X_test_scaled, y_train, y_test\n",
    "    )\n",
    "    if r2 > best_ridge_r2:\n",
    "        best_ridge_r2 = r2\n",
    "        best_ridge_alpha = alpha\n",
    "        best_ridge_model = model\n",
    "        best_ridge_pred = pred\n",
    "        best_ridge_rmse = rmse\n",
    "        best_ridge_mae = mae\n",
    "\n",
    "print(f\"Best Ridge model: alpha={best_ridge_alpha}, R² = {best_ridge_r2:.4f}\")\n",
    "\n",
    "# Lasso Regression with hyperparameter tuning\n",
    "print(\"\\nLasso Regression with hyperparameter tuning:\")\n",
    "lasso_alphas = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "best_lasso_r2 = -np.inf\n",
    "best_lasso_alpha = None\n",
    "best_lasso_model = None\n",
    "\n",
    "for alpha in lasso_alphas:\n",
    "    model, pred, r2, rmse, mae = evaluate_model(\n",
    "        f\"Lasso (alpha={alpha})\", Lasso(alpha=alpha, max_iter=10000),\n",
    "        X_train_scaled, X_test_scaled, y_train, y_test\n",
    "    )\n",
    "    if r2 > best_lasso_r2:\n",
    "        best_lasso_r2 = r2\n",
    "        best_lasso_alpha = alpha\n",
    "        best_lasso_model = model\n",
    "        best_lasso_pred = pred\n",
    "        best_lasso_rmse = rmse\n",
    "        best_lasso_mae = mae\n",
    "\n",
    "print(f\"Best Lasso model: alpha={best_lasso_alpha}, R² = {best_lasso_r2:.4f}\")\n",
    "\n",
    "# Compare models and select the best\n",
    "models = {\n",
    "    \"Linear Regression\": (lr_model, lr_pred, lr_r2, lr_rmse),\n",
    "    \"Ridge\": (best_ridge_model, best_ridge_pred, best_ridge_r2, best_ridge_rmse),\n",
    "    \"Lasso\": (best_lasso_model, best_lasso_pred, best_lasso_r2, best_lasso_rmse)\n",
    "}\n",
    "\n",
    "best_model_name = max(models.keys(), key=lambda k: models[k][2])\n",
    "best_model, best_pred, best_r2, best_rmse = models[best_model_name]\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name} (R² = {best_r2:.4f}, RMSE = {best_rmse:.4f})\")\n",
    "\n",
    "# Visualize actual vs predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, best_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.title(f'{best_model_name}: Actual vs Predicted Anxiety Levels')\n",
    "plt.xlabel('Actual Anxiety Level')\n",
    "plt.ylabel('Predicted Anxiety Level')\n",
    "plt.savefig('plots/actual_vs_predicted.png')\n",
    "plt.close()\n",
    "print(\"Saved actual vs predicted plot to 'plots/actual_vs_predicted.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ac623213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REGRESSION DIAGNOSTICS\n",
      "Shapiro-Wilk test for normality: p-value = 0.0039\n",
      "Residuals are NOT normally distributed\n",
      "Saved regression diagnostic plots to 'plots/regression_diagnostics.png'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/columns.pkl']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nREGRESSION DIAGNOSTICS\")\n",
    "# Calculate residuals\n",
    "residuals = y_test - best_pred\n",
    "\n",
    "# Normality test for residuals\n",
    "stat, p = stats.shapiro(residuals)\n",
    "print(f\"Shapiro-Wilk test for normality: p-value = {p:.4f}\")\n",
    "print(\"Residuals are normally distributed\" if p > 0.05 else \"Residuals are NOT normally distributed\")\n",
    "\n",
    "# Create diagnostic plots\n",
    "plt.figure(figsize=(12, 10))\n",
    "# Residuals vs Fitted\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(best_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('Residuals vs Fitted Values')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "\n",
    "# QQ plot\n",
    "plt.subplot(2, 2, 2)\n",
    "stats.probplot(residuals, plot=plt)\n",
    "plt.title('Normal Q-Q Plot')\n",
    "\n",
    "# Scale-Location plot\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(best_pred, np.abs(residuals), alpha=0.5)\n",
    "plt.title('Scale-Location Plot')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('|Residuals|')\n",
    "\n",
    "# Residuals histogram\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/regression_diagnostics.png')\n",
    "plt.close()\n",
    "print(\"Saved regression diagnostic plots to 'plots/regression_diagnostics.png'\")\n",
    "\n",
    "# Save the best model for deployment\n",
    "joblib.dump(best_model, 'models/anxiety_model.pkl')\n",
    "# Save scaler and columns for deployment\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n",
    "joblib.dump({'num_cols': num_cols, 'cat_cols': cat_cols, 'model_columns': X_train_scaled.columns.tolist()}, 'models/columns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cece0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
